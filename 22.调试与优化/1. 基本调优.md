## 1. 缓存问题
1. 对类/结构体使用关键字进行对齐，以优化缓存行命中。
	- `attribute((aligned(64)))`;或`alignas(64)`，为了使每个核心数据结构独立在缓存行，***提高缓存命中***，一般选`64`。x86和arm64一般是64字节缓存行，32位MCU优先选32字节作为缓存行单位。
	- `struct attribute((aligned(16))) MyStruct {DATA;};`
2. 嵌套循环尽量将大循环放在内部,***避免重复加载***缓存行。
3. `C++11`引入了`alignas`关键字，但是只针对栈上内存有效，`new`的动态内存在`C++17`后才支持`alignas`修饰的类和结构体的实际实现，在此之前并不保证`new`的内存符合`alignas`设置的值。
4. 缓存问题本质是临近区加载，当访问数据的时候会一并缓存其附近的内存。`C++17`中的`<new>`标准库引入了`std::size_t cache_line = std::hardware_destructive_interference_size;`来查看缓存行大小。
    

## 2. 分支预测
1. 逻辑运算转数学运算:
	- ```c++
		if(x > 0) {
			func1( );
		} else {
			func2( );
		}
		/* 优化后 */
		(x > 0) ? func1( ) : func2( );
	  ```

2. 分支顺序优化(***冷热数据***)：
	- 将大概率的分支放在前面，适用于`if else`和`switch`。
	- ***热点数据***问题，***高概率***分支优先处理，放在函数的前半部。
	- ***高概率***`if`放前面有利于分支预测。

---
 - 注：同一个枚举`case`在不同函数的`switch case`中，根据枚举的分布类型和***冷热频率***调整`case`顺序有利于分支预测。

	1. 连续密集型: 123456,底层是跳表,`case`顺序基本无影响，但是热分支在前有***轻微***优化。
	2. 离散型: 1248，***离散型***底层是***线性搜索***，热分支在前有利于预测，较为***明显***的性能优化。
	3. 混合型：为了兼容可读性和性能，***连续区***用枚举***顺序***，***离散区***使用***热分支前置策略***。

3. ***查表***代替***运算和逻辑判断***:
	- 输入输出有固定映射时，查表性能更优。
		- 譬如CRC查表以及使用函数指针数组跳转的状态机机制。
  
## 3. 优化运行效率

1. ***有序***比***无序***好命中，对于二分查找之类的操作，***先排序***是一个好主意。   
2. ***分治***思想，大块化小，最后归并。
3. 合适的容器很重要，复杂度并不代表实际效率，还和数据量有关。
4. `if`上移，尽可能在函数初期就判断条件，***避免多次判断***。 
5. `if`上移配合`for`批处理，尽可能`if`包裹`for`，而不是`for`包裹`if`，***减少判断次数***。

## 4. 内存优化效率

1. ***栈内存***比***堆内存***更快，不要滥用智能指针。
2. ***预分配内存***，容器先预分配合适的大小，***避免填充时的多次扩容***。
3. ***内存池***，使用对象/内存池，避免***频繁分配***内存。

## 5. 流水线与CPU效率

1. ARM单片机采用***多级流水线***，可以加快访问效率。
	- 但遇到***跳转***操作就会***丢弃剩余***指令，***减少跳转***是优化的关键。
2. 通过LR寄存器返回时，是返回的原PC+4的地址，是指示的程序下一行。

## 6. 排查性能瓶颈

1. 使用`perf`和`gdb`来找到***热点函数***，并根据其类型进行代码优化。

# 7. 性能优化小结
1. `cache`缓存比内存的性能更好，要利用`cache`，就要尽可能保持缓存命中，避免`cache miss`。
	1. 对于***单线程***，***高频数据在同一缓存行***可以充分利用***临近预取***特性，提高性能。
	2. 对于***多线程***,具有***并态冲突的高频数据***应当***避免伪共享***,尽可能让***并态访问的数据***在***不同的缓存行***，避免并发冲突。
2. ***跨缓存行时***，***非对齐访问比对齐访问更久***。
3. ***随机访问会使***`cache`***失效***,因此尽量用***顺序访问代替随机***访问。
4. ***跳转操作会导致流水线缓存失效***，如`if`，离散`swith`，虚函数访问，函数指针，`std::function`。
	1. 对于***循环内的条件语句***，***优先过滤数据***，而后循环，减少或避免条件语句分支。
	2. ***少量连续***的`case`会优化为***跳表***，***离散型会被编译器转化为多个***`if`，优化为***查表法***可以提高性能，***查表法符合缓存预取的特性，性能更好***。
	3. ***目标地址不固定无法预测***，***函数指针、虚函数、***`std::function`***、动态库函数***,这些都会导致间接分支预测(IBT)失效。
		1. ***减少虚函数调用和调用层级。***
		2. ***函数指针/虚函数表紧凑化***，让高频函数能被`ICache`缓存。
		3. 避免随机的函数指针调用，将***随机调用改查表调用***，让跳转变得有规律。
		4. ***嵌入式中***，热点函数放进`ICTM/IRAM`（***紧耦合内存***），彻底避免`cache miss`。
5. ***冷热数据分簇***，***避免将冷热数据防止在同一个结构里，导致其过大跨缓存行***，这样访问的时候会加载很多冷数据导致性能下降，***将冷热数据分离，然后用同类容器保存，访问热数据可以充分利用缓存性能，对于冷数据，可以根据相对应的索引去访问，以达到避免冷数据频繁加载的目的***。
6. 循环分块，***对于远超缓存大小的数据，可以通过分片+循环的操作，将每个小块分割到适合缓存的大小，以利用缓存提高性能***。
7. ***显式预取（Explicit Prefetch），主动加载数据到缓存***。若程序的内存访问模式**有规律但硬件预取器无法识别**（如非连续但可预测的访问），可使用**编译器内置的显式预取指令**，主动将后续需要访问的数据加载到缓存，提前规避 Cache Miss。显式预取通过编译器内置函数（如 GCC 的`__builtin_prefetch`）向 CPU 发送预取指令，将指定地址的数据加载到 L1/L2 缓存，后续访问时直接从缓存读取，适合**链表遍历、树遍历**等硬件预取器难以预测的场景。
	-  ```c++
			struct ListNode { 
				   int val; 
				   ListNode* next; 
				   ListNode(int v) : val(v), next(nullptr) {} 
			}; 
			   
			ListNode* createList(int n) { 
				   ListNode* head = new ListNode(0); 
				   ListNode* cur = head; 
				   for (int i = 1; i < n; ++i) { 
					   cur->next = new ListNode(i); 
					   cur = cur->next; 
				} 
					return head; 
			} 
			   // 反例：无预取，链表遍历是随机访问，Cache Miss高 
			int traverseNoPrefetch(ListNode* head) { 
				int sum = 0; 
				ListNode* cur = head; 
				while (cur) { 
					sum += cur->val; 
					cur = cur->next; 
				} 
				return sum; 
			} 
			// 正例：显式预取，提前加载下一个节点到缓存 
			int traverseWithPrefetch(ListNode* head) { 
				int sum = 0; 
				ListNode* cur = head; 
				while (cur) { 
					// 显式预取下一个节点：__builtin_prefetch(地址, 0, 3) 
					// 参数1：要预取的地址；参数2：0=读，1=写；
					// 参数3：预取到L1缓存（0=不缓存只预取，1=L1/L2，2=L2+，3=多级缓存）
				    __builtin_prefetch(cur->next, 0, 3); 
				    sum += cur->val; 
				    cur = cur->next; 
			    } 
			    return sum; 
			}
			```
			
