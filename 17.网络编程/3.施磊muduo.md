# 1. 开源项目推荐
## 1.1 网络层
- muduo
- libevent
## 1.2 缓存层
- redis
- memorycache
## 1.3 存储层
- mySQL
- MongoDB
# 2. IO阻塞与非阻塞
## 2.1 IO阻塞 `block`
1. 默认的`recv`是阻塞的。
	1. `ssize_t recv(int sockfd, void* buf, size_t len,int flags);`,一般`flags`设置为0，未接收到数据的时候是阻塞等待的。
	2. 返回值有三种状态:
		1. `size < 0`,
			1. 若`error == EAGAIN;`,或`error == EWOULDBLOCK`则代表对端没数据发过来。(非阻塞)
			2. `error`为其他值，则代表异常。
		2. `size = 0`,对端正常关闭。
		3. `size > 0`,返回实际接收到的字节数。 
# 3. 五种IO模型
- `recv`实际上就是`read`的特化版本，本质都是内核态对IO的操作。
## 3.1 阻塞`blocking`
- 数据就绪：未就绪阶段，发起IO操作的线程被阻塞（内核挂起）。
- 数据读写：数据就绪成功拷贝后，直接从缓冲区拷贝。
## 3.2 非阻塞`non-blocking`
- 数据就绪：未就绪阶段，直接返回`EAGAIN`或`EWOULDBLOCK`，不会阻塞在内核对IO的`read`。
- 数据读写：需要主动轮询是否有数据，数据就绪后，直接从缓冲区拷贝返回。
## 3.3 IO复用
- IO复用有`select`、`poll`、`epoll`,对`fd`批量监听管理，其IO操作是否阻塞可选。
- 核心是事件通知机制。通过检查fd的事件决定读写还是跳过本次操作。
## 3.4 信号驱动
- 信号驱动是异步的一种，一般采用注册信号处理`handler`回调，通过回调进行通知和处理数据。
- 信号阶段是异步的，`handler`处理数据是同步的。
- 相比`non-blocking`减少了轮询，改用了消息通知机制，减少了api的重复调用，提高了效率。
- 缺陷：存在信号竞争和多线程并态问题，实际很少有服务器后端使用这种方案。
## 3.5 异步`asyn`
- `aio_read`是`linux 2.6 - 4.x`内核的方案，推荐使用`libaio`。仅支持`O_DIRECT`文件IO，不支持`socket`。
- `io_uring`是`linux 5.1+`内核的方案，支持各种fd，对应ubuntu20.04 TLS 以后的版本。
- 这里的异步是系统内核级的异步，并非业务异步(多线程方案)。
# 4. 网络服务器设计要素
## 4.1 线程VS进程
- cpu是以线程为单位运行的，每个物理核心又支持1-2个逻辑线程。
- 提高效率的核心是减少cpu资源浪费，IO密集型要多利用多线程，提高阻塞时的cpu资源利用率。
### 4.1.1 多线程模型
1. 适用于 I/O 密集型业务服务器（如 Web API、数据库访问），这类任务频繁进行网络、磁盘读写，容易造成线程阻塞。
2. 逻辑简单，且线程切换开销比进程低，通过共享内存来线程间通信也容易。
3. IO阻塞的时候会让渡cpu给另一个线程，这使得cpu使用效率比较高，不会白白浪费。
### 4.1.2 多进程模型
1. `Nginx`采用的是单线程+多进程模型。主要用于 I/O 密集型服务（如静态资源分发、反向代理）。
2. 利用 I/O 多路复用（epoll/kqueue）实现高并发、低延迟。
3. 多进程提供更好的隔离性与稳定性（进程间内存隔离，一个崩溃不影响其他）。
4. CPU亲和性强，减少缓存行失效，有效利用多核资源。

